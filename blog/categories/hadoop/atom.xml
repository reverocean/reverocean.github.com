<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hadoop | 海洋的Blog]]></title>
  <link href="http://reverocean.github.com/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://reverocean.github.com/"/>
<<<<<<< HEAD
  <updated>2013-03-29T00:51:25+08:00</updated>
=======
  <updated>2013-03-28T21:31:01+08:00</updated>
>>>>>>> 9c7ac599745a4e17d47b325300d2d0f341b28408
  <id>http://reverocean.github.com/</id>
  <author>
    <name><![CDATA[海洋]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MapReduce in Hadoop]]></title>
    <link href="http://reverocean.github.com/blog/2013/03/23/mapreduce-in-hadoop/"/>
    <updated>2013-03-23T08:29:00+08:00</updated>
    <id>http://reverocean.github.com/blog/2013/03/23/mapreduce-in-hadoop</id>
    <content type="html"><![CDATA[<p>大数据被大家越来越重视，而在大数据的领域里，Hadoop基本上是行业里的事实标准。而MapReduce又是Hadoop中的一个重要特性，这里总结一下MapReduce相关的特性。</p>

<h2>MapReduce的Job是如何工作的</h2>

<p>客户端提交一个Job到Hadoop的MapReduce之后，Hadoop的JobTracker（Hadoop集群中的Master）会把任务分发到TaskTracker（Hadoop集群中的slave）上，先执行Map Task，再执行Reduce的任务。大体流程如下图所示：<br/>
<img src="/images/hadoop/mapreduce/job.jpg" title="" >
 <!--more--></p>

<h2>High Level actors in MapReduce</h2>

<p>如下图所示：<br/>
<img src="/images/hadoop/mapreduce/high_level.jpg" title="" >
在MapReduce里面分为如下几个方面：</p>

<ul>
<li>Input阶段通过InputFormat和RecordReader决定什么样的数据输入到Map中去</li>
<li><ul>
<li>Create split分割Input Data</li>
</ul>
</li>
<li><ul>
<li>Read split通过RecordReader的nextKeyValue为Map输入数据</li>
</ul>
</li>
<li>Map</li>
<li>Partitioning阶段把Map的输出进行Shuffle和Sort</li>
<li>Reduce</li>
<li>Output阶段将Reduce阶段的输出写到data sink</li>
</ul>


<h2>Map</h2>

<ul>
<li>输入：根据split的不同，Map的输入数据可以是文件的一行，也可以是数据库表的一行记录。</li>
<li>输出：零个或者多个key、value对。</li>
</ul>


<h2>Shuffle和Sort</h2>

<p>在MapReduce里，Map处理完Input Data之后的key、value输出需要通过Shuffle和Sort之后，再将数据传递给Reducer。在Shuffle和Sort阶段有两个任务：</p>

<ul>
<li>决定Reducer应该处理哪些key/value对（被称为partitioning）</li>
<li>确定给Reducer的数据是被排过序的
从下图中的例子可以看到，Mapper 1的输出cat, doc1 以及Mapper 2的输出cat, doc2，在经过Shuffle之后被汇总成cat，list(doc1, doc2)。同时，经过Sort之后，传到Reducer里的数据是按照Key排过序的（cat, chipmunk, dog, haster）<br/>
<img src="/images/hadoop/mapreduce/shuffle.jpg" title="" ></li>
</ul>


<h2>Reduce</h2>

<p>处理经过Shuffle和Sort之后的数据，并更具需求输出一个或者多个key/value对。可以输出到HDFS上的一个文件里，也可以输出到NoSQL，或者其他任何Data Sink</p>
]]></content>
  </entry>
  
</feed>
